{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Rigorous Neuro-Symbolic Reasoning\n",
    "\n",
    "This notebook demonstrates a hybrid architecture that addresses key challenges in combining machine learning with formal logic:\n",
    "\n",
    "1. **Symbol Grounding Problem**: How do we map natural language to logical forms?\n",
    "2. **Epistemic vs. Validity**: Separating argument structure from premise truth\n",
    "3. **Confidence Calculus**: Explicit propagation rules\n",
    "4. **Fallacy Detection**: Independent validation of LLM reasoning\n",
    "5. **Unparseable Fragments**: What can't be formalized?\n",
    "\n",
    "## Architecture\n",
    "\n",
    "```\n",
    "ML Backend (Claude + Extended Thinking)\n",
    "           ‚Üì\n",
    "    Integration Layer\n",
    "           ‚Üì\n",
    "Logic Frontend (Formal Proofs + KB)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "# Add agents directory\n",
    "agents_dir = Path.cwd()\n",
    "if agents_dir.name != 'agents':\n",
    "    agents_dir = agents_dir / 'agents'\n",
    "sys.path.insert(0, str(agents_dir))\n",
    "\n",
    "print(f\"‚úÖ Working directory: {Path.cwd()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Symbol Grounding Problem\n",
    "\n",
    "**Challenge**: How does \"All ML models trained on biased data produce biased outputs\" become `‚àÄx(BiasedTraining(x) ‚Üí BiasedOutput(x))`?\n",
    "\n",
    "**Answer**: Context-dependent semantic interpretation with explicit grounding rules."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from logic.grounding import SemanticParser, create_ml_context\n",
    "\n",
    "# Create ML-specific semantic context\n",
    "ml_context = create_ml_context()\n",
    "\n",
    "print(\"üìö ML Semantic Context\")\n",
    "print(f\"\\nPredicates:\")\n",
    "for pred, definition in ml_context.predicates.items():\n",
    "    print(f\"  ‚Ä¢ {pred}: {definition}\")\n",
    "\n",
    "# Parse with context\n",
    "parser = SemanticParser(ml_context)\n",
    "\n",
    "statement = \"All ML models trained on biased data produce biased outputs\"\n",
    "result = parser.parse(statement)\n",
    "\n",
    "print(f\"\\nüìù Parsing: '{statement}'\")\n",
    "print(f\"\\nSuccess: {result.success}\")\n",
    "print(f\"Logical Form: {result.logical_form}\")\n",
    "print(f\"Confidence: {result.confidence:.1%}\")\n",
    "print(f\"\\nAssumptions:\")\n",
    "for assumption in result.assumptions:\n",
    "    print(f\"  ‚Ä¢ {assumption}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Quantification: \"All\" vs. \"Most\" vs. \"Some\" vs. Generic\n",
    "\n",
    "**Challenge**: These have different logical structures and some can't be expressed in first-order logic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_cases = [\n",
    "    (\"All swans are white\", \"Universal: ‚àÄx(Swan(x) ‚Üí White(x))\"),\n",
    "    (\"Some swans are white\", \"Existential: ‚àÉx(Swan(x) ‚àß White(x))\"),\n",
    "    (\"Swans are white\", \"Generic: Gen x(Swan(x) ‚Üí White(x))\"),\n",
    "    (\"Most swans are white\", \"‚ùå UNPARSEABLE in first-order logic\")\n",
    "]\n",
    "\n",
    "print(\"üîç QUANTIFICATION ANALYSIS\\n\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "for statement, expected in test_cases:\n",
    "    result = parser.parse(statement)\n",
    "    \n",
    "    print(f\"\\n'{statement}'\")\n",
    "    print(f\"  Expected: {expected}\")\n",
    "    \n",
    "    if result.success:\n",
    "        print(f\"  ‚úÖ {result.logical_form}\")\n",
    "        print(f\"  Confidence: {result.confidence:.1%}\")\n",
    "        if result.assumptions:\n",
    "            print(f\"  ‚ö†Ô∏è  {result.assumptions[0]}\")\n",
    "    else:\n",
    "        print(f\"  ‚ùå Cannot formalize: {result.unparseable_fragments[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Epistemic Status vs. Logical Validity\n",
    "\n",
    "**Key Distinction**:\n",
    "- **Validity**: Conclusion follows from premises (structural correctness)\n",
    "- **Soundness**: Premises are actually true (factual correctness)\n",
    "\n",
    "An argument can be valid but unsound (Socrates is a fish)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from logic.epistemic import ValidityChecker\n",
    "\n",
    "checker = ValidityChecker()\n",
    "\n",
    "# Example: Valid but absurd\n",
    "print(\"üîπ CASE 1: Valid but Absurd\\n\")\n",
    "print(\"Premise 1: If Socrates is a fish, then Socrates can swim\")\n",
    "print(\"Premise 2: Socrates is a fish\")\n",
    "print(\"Conclusion: Socrates can swim\")\n",
    "\n",
    "status = checker.check_modus_ponens(\n",
    "    \"If Socrates is a fish, then Socrates can swim\",\n",
    "    \"Socrates is a fish\",\n",
    "    \"Socrates can swim\"\n",
    ")\n",
    "\n",
    "print(f\"\\nValidity: {status.validity.value} (confidence: {status.validity_confidence:.1%})\")\n",
    "print(f\"Soundness: {status.soundness.value}\")\n",
    "print(f\"Justification: {status.validity_justification}\")\n",
    "print(f\"\\nüí° This argument is VALID but UNSOUND\")\n",
    "print(f\"   The structure is correct, but premise 2 is false.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Fallacy Detection\n",
    "\n",
    "**Challenge**: LLMs might label reasoning as \"modus ponens\" when it's actually \"affirming the consequent\" (a fallacy).\n",
    "\n",
    "**Solution**: Independent validation that doesn't trust the LLM's self-labeling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from logic.epistemic import ConfidenceCalculator\n",
    "\n",
    "calc = ConfidenceCalculator()\n",
    "\n",
    "print(\"üîç FALLACY DETECTION\\n\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Example 1: Affirming the consequent\n",
    "print(\"\\nüìã Example 1: Missing Universal Quantifier\")\n",
    "premises = [\"Tech companies are successful\", \"Google is a tech company\"]\n",
    "conclusion = \"Google is successful\"\n",
    "claimed_rule = \"modus_ponens\"\n",
    "\n",
    "print(f\"Premises: {premises}\")\n",
    "print(f\"Conclusion: {conclusion}\")\n",
    "print(f\"Claimed Rule: {claimed_rule}\")\n",
    "\n",
    "fallacy = calc.detect_fallacy(premises, conclusion, claimed_rule)\n",
    "\n",
    "if fallacy:\n",
    "    print(f\"\\nüö® FALLACY DETECTED: {fallacy}\")\n",
    "    print(f\"\\nProblem: Premise says 'Tech companies are successful' (generic/existential)\")\n",
    "    print(f\"         Valid form requires: 'ALL tech companies are successful'\")\n",
    "    print(f\"         This is affirming the consequent, not modus ponens.\")\n",
    "else:\n",
    "    print(\"\\n‚úÖ No fallacy detected\")\n",
    "\n",
    "# Example 2: Hasty generalization\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"\\nüìã Example 2: Hasty Generalization\")\n",
    "premises2 = [\"Some swans I've seen are white\"]\n",
    "conclusion2 = \"All swans are white\"\n",
    "claimed_rule2 = \"universal_generalization\"\n",
    "\n",
    "print(f\"Premises: {premises2}\")\n",
    "print(f\"Conclusion: {conclusion2}\")\n",
    "print(f\"Claimed Rule: {claimed_rule2}\")\n",
    "\n",
    "fallacy2 = calc.detect_fallacy(premises2, conclusion2, claimed_rule2)\n",
    "\n",
    "if fallacy2:\n",
    "    print(f\"\\nüö® FALLACY DETECTED: {fallacy2}\")\n",
    "    print(f\"\\nProblem: Generalizing from 'some' to 'all' without sufficient sample.\")\n",
    "else:\n",
    "    print(\"\\n‚úÖ No fallacy detected\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Explicit Confidence Propagation\n",
    "\n",
    "**Challenge**: If I chain 10 steps each at 0.9 confidence, what's the final confidence?\n",
    "\n",
    "**Answer**: Explicit calculus with multiple methods:\n",
    "- Conjunctive (AND): Product rule\n",
    "- Disjunctive (OR): Complement rule\n",
    "- Inference steps: Weighted by rule type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"üìä CONFIDENCE PROPAGATION\\n\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Show degradation with chain length\n",
    "print(\"\\nüìâ Conjunctive Chain Degradation:\")\n",
    "print(\"(Each step at 0.9 confidence)\\n\")\n",
    "\n",
    "for length in [1, 3, 5, 10, 20]:\n",
    "    confidences = [0.9] * length\n",
    "    result = calc.conjunctive_chain(confidences)\n",
    "    print(f\"  {length:2d} steps ‚Üí {result:.1%}\")\n",
    "\n",
    "print(\"\\nüí° Observation: Confidence degrades exponentially\")\n",
    "print(\"   10 steps at 0.9 ‚Üí only 35% confidence!\")\n",
    "print(\"   This is why shorter proofs are preferred.\")\n",
    "\n",
    "# Show multi-step breakdown\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"\\nüìã Multi-Step Reasoning Example:\\n\")\n",
    "print(\"P1: All ML models trained on biased data produce biased outputs (0.7)\")\n",
    "print(\"P2: GPT-4 was trained on biased data (0.6)\")\n",
    "print(\"R1: Universal instantiation (0.9)\")\n",
    "print(\"C: GPT-4 produces biased outputs (?)\")\n",
    "\n",
    "breakdown = calc.multi_step_chain(\n",
    "    premise_confidences=[0.7, 0.6],\n",
    "    rule_confidences=[0.9],\n",
    "    rule_types=[\"universal_instantiation\"]\n",
    ")\n",
    "\n",
    "print(f\"\\nüî¨ Confidence Breakdown:\")\n",
    "print(f\"  Logical Confidence: {breakdown.logical_confidence:.1%}\")\n",
    "print(f\"    (How confident are we the argument is valid?)\")\n",
    "print(f\"  Source Confidence: {breakdown.source_confidence:.1%}\")\n",
    "print(f\"    (How confident are we the premises are true?)\")\n",
    "print(f\"  Propagation Method: {breakdown.propagation_method}\")\n",
    "print(f\"  Chain Length: {breakdown.chain_length}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Modality Detection\n",
    "\n",
    "**Challenge**: \"Most birds can fly\" and \"John believes Mary is happy\" can't be expressed in first-order logic.\n",
    "\n",
    "**Solution**: Detect when specialized logics are needed and report unparseable fragments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"üîç MODALITY DETECTION\\n\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "modality_cases = [\n",
    "    (\"All humans are mortal\", \"First-order logic\"),\n",
    "    (\"Most birds can fly\", \"Requires higher-order logic\"),\n",
    "    (\"John believes Mary is happy\", \"Requires epistemic logic\"),\n",
    "    (\"It's illegal to drive without insurance\", \"Requires deontic logic\"),\n",
    "    (\"The water boiled because it was heated\", \"Requires causal logic\")\n",
    "]\n",
    "\n",
    "for statement, logic_needed in modality_cases:\n",
    "    result = parser.parse(statement)\n",
    "    \n",
    "    print(f\"\\n'{statement}'\")\n",
    "    print(f\"  Required: {logic_needed}\")\n",
    "    \n",
    "    if result.modality:\n",
    "        print(f\"  Modality: {result.modality.value}\")\n",
    "    \n",
    "    if result.success:\n",
    "        print(f\"  ‚úÖ {result.logical_form}\")\n",
    "    else:\n",
    "        print(f\"  ‚ùå {result.unparseable_fragments[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Full Reasoning Agent Integration\n",
    "\n",
    "Putting it all together: A reasoning agent that:\n",
    "1. Parses with context-aware grounding\n",
    "2. Validates argument structure independently\n",
    "3. Propagates confidence explicitly\n",
    "4. Detects fallacies\n",
    "5. Reports unparseable fragments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from logic import ReasoningAgent, LogicType\n",
    "\n",
    "# Create agent with first-order logic\n",
    "agent = ReasoningAgent(\n",
    "    name=\"Rigorous Reasoner\",\n",
    "    system_prompt=\"Combines ML reasoning with formal logic validation\",\n",
    "    logic_framework=LogicType.FIRST_ORDER,\n",
    "    reasoning_depth=3,\n",
    "    logic_weight=0.75,  # Prioritize logic over consensus\n",
    "    verbose=False\n",
    ")\n",
    "\n",
    "# Add knowledge with provenance\n",
    "print(\"üìö Building Knowledge Base...\\n\")\n",
    "\n",
    "agent.add_knowledge(\n",
    "    \"All software engineers write code\",\n",
    "    source=\"domain_knowledge\",\n",
    "    confidence=1.0\n",
    ")\n",
    "\n",
    "agent.add_knowledge(\n",
    "    \"Alice is a software engineer\",\n",
    "    source=\"user_input\",\n",
    "    confidence=1.0\n",
    ")\n",
    "\n",
    "# Reason\n",
    "print(\"‚ùì Query: What can we conclude about Alice?\\n\")\n",
    "\n",
    "result = agent.reason(\"What can we conclude about Alice?\")\n",
    "\n",
    "# Display results\n",
    "print(\"=\" * 70)\n",
    "print(\"üìä REASONING RESULT\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "print(f\"\\nConclusion: {result['conclusion']}\")\n",
    "print(f\"Formal: {result['formal_conclusion']}\")\n",
    "print(f\"Confidence: {result['confidence']:.1%}\")\n",
    "\n",
    "print(f\"\\nüîó Reasoning Chain:\")\n",
    "for i, step in enumerate(result['reasoning_chain'], 1):\n",
    "    print(f\"  {i}. {step['premise']}\")\n",
    "    print(f\"     ‚Üí [{step['rule']}]\")\n",
    "    print(f\"     ‚Üí {step['conclusion']}\")\n",
    "    print(f\"     (confidence: {step['confidence']:.1%})\")\n",
    "\n",
    "print(f\"\\n‚úÖ Knowledge Validation:\")\n",
    "val = result['knowledge_validation']\n",
    "print(f\"  Valid: {val['valid']}\")\n",
    "print(f\"  KB Confidence: {val['confidence']:.1%}\")\n",
    "print(f\"  Sources: {', '.join(val['sources'])}\")\n",
    "\n",
    "# Show formal argument\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"üìú FORMAL ARGUMENT\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "formatter = agent.argument_builder.formatter\n",
    "print(formatter.format_argument(result['formal_argument']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "This neuro-symbolic system addresses key challenges:\n",
    "\n",
    "### ‚úÖ Symbol Grounding\n",
    "- Context-dependent semantic interpretation\n",
    "- Explicit predicate definitions\n",
    "- Grounding rules for term mapping\n",
    "\n",
    "### ‚úÖ Epistemic vs. Validity\n",
    "- Separate tracking of structural validity and factual truth\n",
    "- Valid arguments can have false premises\n",
    "- Invalid arguments can have true premises\n",
    "\n",
    "### ‚úÖ Confidence Calculus\n",
    "- Explicit propagation rules (product, complement)\n",
    "- Multi-dimensional confidence (logical, empirical, source)\n",
    "- Chain length effects are visible and justified\n",
    "\n",
    "### ‚úÖ Fallacy Detection\n",
    "- Independent validation (doesn't trust LLM self-labeling)\n",
    "- Detects affirming consequent, hasty generalization, etc.\n",
    "- Checks for missing quantifiers\n",
    "\n",
    "### ‚úÖ Unparseable Fragments\n",
    "- Gracefully handles what can't be formalized\n",
    "- Reports which specialized logic is needed\n",
    "- Makes assumptions explicit\n",
    "\n",
    "## Next Steps\n",
    "\n",
    "For production systems:\n",
    "1. Full NLP parser (dependency trees, semantic roles)\n",
    "2. Automated theorem proving (Coq, Lean, Isabelle)\n",
    "3. Higher-order logic for \"most\", \"few\"\n",
    "4. Modal logics for beliefs, time, causation\n",
    "5. Ground truth oracles (external validation)\n",
    "6. Contradiction detection and resolution"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
